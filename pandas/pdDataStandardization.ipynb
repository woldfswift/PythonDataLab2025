{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ee87fb1c459452e",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 数据标准化与变换数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c3ee62bfce50bc",
   "metadata": {},
   "source": [
    "# 数据标准化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc59f7734324afd9",
   "metadata": {},
   "source": [
    "## 什么是数据标准化？为什么要进行数据标准化？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c114614ce677105",
   "metadata": {},
   "source": [
    "数据标准化就是通过数学方法，把不同量纲或数量级的数据转化到统一的尺度，使它们更具可比性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80947409368ef796",
   "metadata": {},
   "source": [
    "为什么需要数据标准化\n",
    "- 消除量纲差异：不同指标可能有不同的单位（如米、千克、秒），直接比较会失真。\n",
    "- 避免数量级影响：某些变量数值范围很大，会在分析中占主导地位，而小范围变量可能被忽视。\n",
    "- 提高模型效果：在机器学习中，标准化能帮助算法更快收敛，提高准确性。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee632432a4e1b09",
   "metadata": {},
   "source": [
    "应用场景\n",
    "- 机器学习：如 KNN、SVM、神经网络等算法对数据尺度敏感。\n",
    "- 综合评价：在医疗、经济、教育等领域，多个指标需要统一比较。\n",
    "- 图像处理：像素值标准化便于模型识别。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6efe121727b09aa",
   "metadata": {},
   "source": [
    "## 数据标准化的常用方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab95db49",
   "metadata": {},
   "source": [
    "### 离差标准化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90d1421",
   "metadata": {},
   "source": [
    "离差标准化（也叫 极差标准化 / Min-Max Normalization）是通过数据的 最大值 和 最小值 来进行线性变换，把数据映射到一个固定区间（通常是 [0,1] 或 [-1,1]）。\n",
    "\n",
    "公式如下：\n",
    "\n",
    "$$\n",
    "X'=\\frac{X-X_{min}}{X_{max}-X_{min}}\n",
    "$$ \n",
    "\n",
    "- $ X $：原始数据\n",
    "- $ X_{min} $：样本中的最小值\n",
    "- $ X_{max} $：样本中的最大值\n",
    "- $ X' $：标准化后的数据\n",
    "\n",
    "特点\n",
    "- 范围固定：通常压缩到 [0,1] 区间，便于比较。\n",
    "- 保持比例关系：数据之间的相对差异不变。\n",
    "- 对异常值敏感：如果存在极端值，整个缩放区间会被拉伸。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a89a771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pay = pd.read_csv('pd_data/user_pay_info.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541f931f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义离差标准化函数\n",
    "def min_max_scale(data):\n",
    "    data = (data - data.min()) / (data.max() - data.min())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa49840a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_min_max = min_max_scale(pay['每月支出'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a6459b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pay['每月支出']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaaff5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_min_max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c112454",
   "metadata": {},
   "source": [
    "### 标准差标准化数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8a4e93",
   "metadata": {},
   "source": [
    "标准差标准化（也叫 Z-score 标准化 或 零均值标准化）\n",
    "\n",
    "是通过数据的 均值 和 标准差 来调整数据，使其转化为一个 均值为 0、标准差为 1 的分布。\n",
    "\n",
    "公式如下：\n",
    "\n",
    "\n",
    "$$\n",
    " X'=\\frac{X-\\mu }{\\sigma } \n",
    "$$\n",
    "\n",
    "- $ X$：原始数据\n",
    "- $ \\mu $：样本均值\n",
    "- $ \\sigma $ ：样本标准差\n",
    "- $ X' $：标准化后的数据\n",
    "\n",
    "特点\n",
    "- 均值为 0：标准化后的数据中心在零点。\n",
    "- 方差为 1：数据分布的尺度统一。\n",
    "- 消除量纲影响：不同单位（如米、千克）的数据可以放在同一模型中比较。\n",
    "- 对异常值敏感：因为标准差受极端值影响，离差标准化在存在离群点时可能不稳定。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733c196f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义标准差标准化函数\n",
    "def standard_scaler(data):\n",
    "    data = (data - data.mean()) / data.std()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb7d604",
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_standard = standard_scaler(pay['每月支出'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1d37af",
   "metadata": {},
   "outputs": [],
   "source": [
    "pay['每月支出']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a785457a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_standard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa438d1",
   "metadata": {},
   "source": [
    "### 小数定标标准化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f42793",
   "metadata": {},
   "source": [
    "小数定标标准化是通过 移动数据的小数点位置 来实现标准化的一种方法。它的核心思想是：\n",
    "**让数据的绝对值不超过 1。**\n",
    "\n",
    "公式如下：\n",
    "$$\n",
    "X'=\\frac{X}{10^j}\n",
    "$$\n",
    "\n",
    "其中：\n",
    "- $ X $：原始数据\n",
    "- $ j $：需要移动的小数点位数\n",
    "- $ X $'：标准化后的数据\n",
    "\n",
    "选择$ j $的原则是：\n",
    "$$ \\max (|X'|)<1 $$\n",
    "即标准化后所有数据的绝对值都小于 1。\n",
    "\n",
    "特点\n",
    "- 简单直观：只需确定小数点移动的位数。\n",
    "- 快速计算：不依赖均值、方差或最大最小值。\n",
    "- 适用范围有限：主要用于数据范围已知且分布较均匀的情况。\n",
    "- 对异常值敏感：极端值会影响小数点移动的位数。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4fbd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义小数定标标准化函数\n",
    "import numpy as np\n",
    "def decimal_scaler(data):\n",
    "    data = data / 10 ** np.ceil(np.log10(data.abs().max()))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7878e43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_decimal = decimal_scaler(pay['每月支出'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbb21db",
   "metadata": {},
   "outputs": [],
   "source": [
    "pay['每月支出']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27abdac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_decimal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e96930",
   "metadata": {},
   "source": [
    "# 变换数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedfc938",
   "metadata": {},
   "source": [
    "在数据清洗工作中，数据变换是一个非常重要的环节，它的目的不仅仅是“让数据看起来整齐”，而是为了让后续分析和建模更加科学、准确。\n",
    "\n",
    "为什么要进行数据变换\n",
    "- 消除量纲差异\n",
    "    - 不同字段可能有不同的单位或数量级（如收入以万元计、年龄以岁计），直接比较会失真。通过标准化或归一化，可以让它们处于同一尺度。\n",
    "- 提高模型性能\n",
    "    - 许多机器学习算法（如 KNN、SVM、神经网络）对数据的尺度敏感。如果不变换，某些特征可能因为数值范围大而主导模型，导致偏差。\n",
    "- 满足统计假设\n",
    "    - 一些统计方法要求数据满足特定分布（如正态分布）。通过对数变换、平方根变换等，可以让数据更接近这些假设条件。\n",
    "- 减少偏态和异常值影响\n",
    "    - 数据常常存在偏态分布或极端值。适当的变换（如对数变换）可以压缩大值的影响，使分布更平滑。\n",
    "- 便于解释和比较\n",
    "    - 统一后的数据更容易进行跨指标比较，也更容易在可视化中展示。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e1775e",
   "metadata": {},
   "source": [
    "## 哑变量处理类别类型数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008b9ca2",
   "metadata": {},
   "source": [
    "什么是哑变量处理\n",
    "- 类别型数据（如性别、颜色、地区）不能直接用于大多数统计模型或机器学习算法，因为它们是非数值型。\n",
    "- 哑变量处理就是把类别型数据转化为数值型数据的一种方法。\n",
    "- 核心思想：用 0/1（二进制）变量 来表示某个类别是否出现。\n",
    "\n",
    "在pandas中，可以使用get_dummies函数对类别类型进行哑变量处理\n",
    "```\n",
    "pd.get_dummies(data, prefix=None, prefix_sep='_', dummy_na=False, columns=None, drop_first=False)\n",
    "```\n",
    "\n",
    "常用参数说明\n",
    "- data：输入的 DataFrame 或 Series。\n",
    "- columns：指定要转换的列，默认对所有类别型列进行处理。\n",
    "- prefix：为生成的哑变量列添加前缀。\n",
    "- prefix_sep：前缀和类别名之间的分隔符，默认是 _。\n",
    "- dummy_na：是否为缺失值生成一列，默认 False。\n",
    "- drop_first：是否删除第一个类别，避免虚拟变量陷阱（多重共线性）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634f143b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "all_info = pd.read_csv('pd_data/user_all_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f472bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "live_type = all_info['居住类型']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27ae284",
   "metadata": {},
   "outputs": [],
   "source": [
    "live_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31b2342",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(live_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26756482",
   "metadata": {},
   "source": [
    "## 离散化连续型变量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3e42df",
   "metadata": {},
   "source": [
    "在数据分析中，离散化连续型变量（也叫分箱 binning）是一种常见的预处理方法。它的核心思想是：把连续的数值变量划分为若干区间，再用类别型变量来表示。\n",
    "\n",
    "为什么要离散化连续型变量\n",
    "- 简化模型\n",
    "    - 连续变量可能取值范围很大，离散化后可以减少复杂度，让模型更容易处理。\n",
    "- 增强可解释性\n",
    "    - 离散化后的变量更容易被人理解。例如，把“年龄”分为“青年、中年、老年”，比直接用数值更直观。\n",
    "- 处理非线性关系\n",
    "    - 某些变量与目标变量的关系不是线性的。通过分箱，可以更好地捕捉这种关系。\n",
    "- 减少噪声影响\n",
    "    - 连续变量可能受测量误差或波动影响，离散化后能降低噪声对模型的干扰。\n",
    "- 满足算法需求\n",
    "    - 一些算法或统计方法（如决策树、朴素贝叶斯）对类别型变量更友好，离散化能提高适用性。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88f5b5f",
   "metadata": {},
   "source": [
    "常见离散化方法\n",
    "- 等宽分箱（等宽法）：把数值范围平均分成若干区间。\n",
    "- 等频分箱（等频法）：保证每个区间内样本数量大致相同。\n",
    "- 基于聚类的分箱（聚类分析法）：用聚类算法划分区间。\n",
    "- 基于业务规则的分箱：如年龄分为“青年、中年、老年”。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da1297d",
   "metadata": {},
   "source": [
    "### 等宽法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ad8702",
   "metadata": {},
   "source": [
    "等宽分箱（Equal-width Binning） 是一种常见的连续型变量离散化方法。它的核心思想是：把数据的取值范围按照固定的宽度划分为若干个区间，每个区间的宽度相同。\n",
    "\n",
    "原理：\n",
    "假设数据的最小值是 X_{min}，最大值是 X_{max}，需要分成 k 个区间。\n",
    "每个区间的宽度为：\n",
    "$$\n",
    "w=\\frac{X_{max}-X_{min}}{k}\n",
    "$$\n",
    "然后按照这个宽度，把整个区间划分为：\n",
    "$$\n",
    "[X_{min},X_{min}+w),[X_{min}+w,X_{min}+2w),\\dots ,[X_{min}+(k-1)w,X_{max}]\n",
    "$$\n",
    "特点\n",
    "- 简单直观：只需确定分箱数量 k，计算区间宽度即可。\n",
    "- 区间宽度相同：保证划分均匀。\n",
    "- 样本分布不均衡：如果数据集中在某些区间，可能导致某些箱子样本很多，另一些箱子样本很少。\n",
    "- 对异常值敏感：极端值会拉大区间范围，导致分箱效果不理想。\n",
    "\n",
    "\n",
    "在pandas中，提供了cut函数进行连续数据的等宽离散\n",
    "```\n",
    "pd.cut(x, bins, right=True, labels=None, retbins=False, precision=3, include_lowest=False)\n",
    "```\n",
    "参数说明\n",
    "- x：要分箱的数组或 Series。\n",
    "- bins：分箱规则，可以是：\n",
    "    - 整数：表示要分成多少个等宽区间。\n",
    "    - 序列：表示具体的分割点。\n",
    "- right：是否包含右边界，默认 True。\n",
    "- labels：为分箱结果指定标签，默认返回区间对象。\n",
    "- retbins：是否返回分箱的边界值。\n",
    "- precision：保留小数位数。\n",
    "- include_lowest：是否包含最左边界。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b433fe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_cut = pd.cut(all_info['年龄'], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bbc38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_cut.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0233a1",
   "metadata": {},
   "source": [
    "### 等频法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d1e01d",
   "metadata": {},
   "source": [
    "等频分箱（Equal-frequency Binning） 是一种常见的连续型变量离散化方法。它的核心思想是：把数据按照样本数量均匀分配到若干个区间，每个区间包含的样本数大致相同。\n",
    "\n",
    "原理:\n",
    "\n",
    "假设有 n 个样本，需要分成 k 个区间。\n",
    "- 每个区间大约包含$ \\frac{n}{k} $个样本。\n",
    "- 分箱的边界由数据的排序结果决定，而不是固定的数值范围。\n",
    "\n",
    "与 **等宽分箱** 不同：\n",
    "- 等宽分箱 → 区间宽度相同，但样本数可能差异很大。\n",
    "- 等频分箱 → 区间样本数相同，但区间宽度可能差异很大。\n",
    "\n",
    "特点:\n",
    "- 样本分布均衡：每个箱子里样本数量接近，避免某些箱子过于稀疏。\n",
    "- 区间宽度不固定：如果数据分布不均匀，某些区间可能很窄，某些区间可能很宽。\n",
    "- 适合偏态分布：能保证每个分箱都有足够的数据，减少噪声影响。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1989657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 自定义等频法离散化函数\n",
    "def same_rate_cut(data, k):\n",
    "    w = data.quantile(np.arange(0, 1 + 1.0 / k, 1.0 / k))\n",
    "    data = pd.cut(data, w)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a70cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_same_rate = same_rate_cut(all_info['年龄'], 5).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051e1d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_same_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2d55bd",
   "metadata": {},
   "source": [
    "### 据类分析法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61accaf8",
   "metadata": {},
   "source": [
    "基于聚类的分箱（Clustering-based Binning） 是一种利用聚类算法对连续型变量进行离散化的方法。它不同于等宽分箱和等频分箱，不是简单地按照数值范围或样本数量来划分，而是通过聚类算法自动发现数据的分布结构，再将数据划分为若干类别。\n",
    "\n",
    "原理\n",
    "- 选择聚类算法：常用的有 K-means、层次聚类等。\n",
    "- 设定分箱数量：比如希望分成 k 个箱子，就设定聚类的簇数为 k。\n",
    "- 聚类过程：算法根据数据的相似性，把数值划分到不同的簇。\n",
    "- 形成分箱：每个簇对应一个分箱，簇的边界由聚类结果决定。\n",
    "\n",
    "特点\n",
    "- 自适应性强：分箱结果由数据分布决定，更符合实际情况。\n",
    "- 能捕捉复杂分布：适合数据呈现非均匀分布或多峰分布的场景。\n",
    "- 比等宽/等频更智能：避免某些箱子过于稀疏或过于密集。\n",
    "- 计算复杂度高：需要运行聚类算法，计算量比简单分箱大。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e59a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义数据K-Means聚类离散化函数\n",
    "def kmean_cut(data, k):\n",
    "    from sklearn.cluster import KMeans  # 引入K-Means\n",
    "    # 建立模型\n",
    "    kmodel = KMeans(n_clusters=k)\n",
    "    kmodel.fit(data.values.reshape((len(data), 1)))  # 训练模型\n",
    "    # 输出聚类中心并排序\n",
    "    c = pd.DataFrame(kmodel.cluster_centers_).sort_values(0)   \n",
    "    w = c.rolling(2).mean().iloc[1:]  # 相邻两项求中点，作为边界点\n",
    "    w = [0] + list(w[0]) + [data.max()]  # 把首末边界点加上\n",
    "    data = pd.cut(data, w)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2377e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用户年龄等频法离散化\n",
    "age_dropna = all_info['年龄'].dropna()\n",
    "age_kmeans = kmean_cut(age_dropna, 5).value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe95c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_kmeans"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
